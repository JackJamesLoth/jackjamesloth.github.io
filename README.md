I am currently pursuing a PhD in AI and Music at the Centre for Digital Music (C4DM) at Queen Mary University of London. My research focuses on generative AI for guitars. I also write and produce metal music under the name Serval.

[Google Scholar](https://scholar.google.com/citations?user=_sE33TkAAAAJ&hl=en&oi=sra) | 
[GitHub](https://github.com/JackJamesLoth) |
[Twitter](https://x.com/jackjamesloth)
# Current Projects
### Guitar Synthesis
This project explores synthesising electric guitar using a diffusion transformer and a guitar-specific input format. We are targeting a publication at ISMIR 2025.
### GOAT
Targeting a publication at ISMIR 2025.
### Guitar Timbre Project
This is a large and significant project but I unfortunately cannot share too much about it until we publish. Stay tuned!
### HEL9000
Dominating the cosmos with AI metal ðŸ¤˜

[Soundcloud](https://soundcloud.com/hel9000) |
[Instagram](https://www.instagram.com/hel9000ismetal/) |
[Twitter](https://x.com/HEL9000ismetal)
### Serval EP II
The second EP from my progressive metal project Serval. While not an academic project, it allows me to showcase my musical and technical skills in music production and audio engineering, as well as engage creatively with music outside of the domain of MIR. At the time of writing, this project is nearing the end of recording.

[Bandcamp](https://servalprog.bandcamp.com/album/village) |
[Instagram](https://www.instagram.com/servalprog/) |
[YouTube](https://www.youtube.com/@servalprog) |
[Spotify](https://open.spotify.com/artist/72mMU9TdSG6L9xXCfy7Q69?si=DWqenwd6T6earCEZvBFRmg)
# Previous projects/publications
### (2024) Analysis of MIDI as Input Representations for Guitar Synthesis
We analyse the effectiveness of MIDI as an input representation in the task of guitar synthesis. Given the results, we argue that more comprehensively annotated datasets are needed for this task.

This paper was published in the proceedings of **DMRN+19: Digital Music Research Network One-day Workshop 2024** (first author).

### (2024) Between the AI and Me: Analysing Listeners' Perspectives on AI-and Human-Composed Progressive Metal Music
Generative AI models have recently blossomed, significantly impacting artistic and musical traditions. Research investigating how humans interact with and deem these models is therefore crucial. Through a listening and reflection study, we explore participants' perspectives on AI- vs human-generated progressive metal, in symbolic format, using rock music as a control group. AI-generated examples were produced by ProgGP, a Transformer-based model. We propose a mixed methods approach to assess the effects of generation type (human vs. AI), genre (progressive metal vs. rock), and curation process (random vs. cherry-picked). This combines quantitative feedback on genre congruence, preference, creativity, consistency, playability, humanness, and repeatability, and qualitative feedback to provide insights into listeners' experiences. A total of 32 progressive metal fans completed the study. Our findings validate the use of fine-tuning to achieve genre-specific specialization in AI music generation, as listeners could distinguish between AI-generated rock and progressive metal. Despite some AI-generated excerpts receiving similar ratings to human music, listeners exhibited a preference for human compositions. Thematic analysis identified key features for genre and AI vs. human distinctions. Finally, we consider the ethical implications of our work in promoting musical data diversity within MIR research by focusing on an under-explored genre.

This paper was published at **ISMIR 2024, the 25th International Society for Music Information Retrieval** (second author, equal contributions).

[PDF link](https://arxiv.org/pdf/2307.05328) |
[Video presentation](https://www.youtube.com/watch?v=cAMfKEkxcB4)
### (2024) AI Song Contest 2024
We submitted a song from my AI metal band HEL9000, achieving 3rd place by jury vote and 5th place by popular vote. The song was created using the fine-tuned progressive metal tablature generation model from the ProgGP paper (see below). The guitar and bass parts were learned and recorded, and vocals were sung/screamed using ChatGPT inspired lyrics. The drums were programmed using sample libraries.

[Song submission](https://soundcloud.com/hel9000/binary-b1o0d)
### (2024) Reflection Across AI-based Music Composition
We reflect on the process of creating an AI metal song using a similar process to the ProgGP paper (see below). This was part of a larger paper about AI-based music composition, with reflections from several other AI music created. I was only involved with the part on my own song however. This paper was published at the **16th Conference on Creativity & Cognition**. The song was eventually expanded into a full song which was used as our submission for the AI Song Contest 2024.

[PDF link](https://qmro.qmul.ac.uk/xmlui/bitstream/handle/123456789/97327/Ford%20Reflection%20Across%20AI-based%202024%20Accepted.pdf?sequence=2) |
[Song demo](https://soundcloud.com/hel9000/binary-b1o0d)
### (2023) ProgGP: from GuitarPro Tablature Neural Generation to Progressive Metal Production
Recent work in the field of symbolic music generation has shown value in using a tokenization based on the GuitarPro format, a symbolic representation supporting guitar expressive attributes, as an input and output representation. We extend this work by fine-tuning a pre-trained Transformer model on ProgGP, a custom dataset of 173 progressive metal songs, for the purposes of creating compositions from that genre through a human-AI partnership. Our model is able to generate multiple guitar, bass guitar, drums, piano and orchestral parts. We examine the validity of the generated music using a mixed methods approach by combining quantitative analyses following a computational musicology paradigm and qualitative analyses following a practice-based research paradigm. Finally, we demonstrate the value of the model by using it as a tool to create a progressive metal song, fully produced and mixed by a human metal producer based on AI-generated music.

This paper was published at **CMMR 2023, the 16th International Symposium on Computer Music Multidisciplinary Research** (first author).

[PDF link](https://arxiv.org/pdf/2307.05328) |
[Song demo](https://youtu.be/CJ4ePhs9rs4?si=4_THx3nvhkOUoe6s) |
[Process video](https://youtu.be/E5Lykp-dFLw?si=uwV9OoiEV4OvzrRJ)
### (2023) Playing Style Affects Steel-String Acoustic Guitar Timbre
A listening test was performed to investigate the effects of playing style on the perceived timbre of steel string acoustic guitars. This paper was published at the **Timbre 2023, the 3rd International Conference on Timbre** (first author).

[PDF link](https://qmro.qmul.ac.uk/xmlui/bitstream/handle/123456789/89318/Loth%20Playing%20Style%20Affects%202023%20Accepted.pdf?sequence=2) |
[GitHub repo](https://github.com/JackJamesLoth/TimbreListeningTest)
### (2022) Serval - Village EP
The first release of my solo progressive metal project Serval. While not necessarily an academic work, the project showcases my musical and technical skills in music production and audio engineering. It has also garnered a small fan base for my project!

[Bandcamp](https://servalprog.bandcamp.com/album/village) |
[Instagram](https://www.instagram.com/servalprog/) |
[YouTube](https://youtu.be/86Yiyxo9KRg?si=rwz5UalYVgoiwXws) |
[Spotify](https://open.spotify.com/album/12TamykVy2S9Ugw7yfy5HE?si=JlO49jzgTTGRFrioqOr07g)

### (2021) RMRI Paper Implementation
Re-implementation of [Timbre analysis of music audio signals with convolutional neural networks](https://ieeexplore.ieee.org/document/8081710) paper as coursework for RMRI module.

[GitHub repo](https://github.com/JackJamesLoth/RMRI_Coursework3)
### (2021) Building a Real-Time Digital Guitar Amplifier Using Deep Learning
Trained a CNN to emulate various guitar amplifiers. I also implemented it as a real-time plugin using the JUCE framework. The plugin had better performance than similar implementations of this kind of architecture as well as commercial amplifier sim plugins (at least at the time). 

[GitHub repo](https://github.com/JackJamesLoth/AmpProject/tree/main)
### (2020) Visualising Album Popularity with Musical Features
A website which allows the user to visualise the popularity of albums from a given artist and how they correlate with music features (given by the Spotify API). This was made as a final project for my Data Visualisation class during my MS in Computer Science and Engineering.

[GitHub repo](https://github.com/JackJamesLoth/CSE5544_FinalProject)
